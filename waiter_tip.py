# -*- coding: utf-8 -*-
"""Waiter Tip.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1J-Qhwcr0pagOGfJWNbDSE6ImwTIUAiOt

# **Waiter’s Tip Prediction**

The food server of a restaurant recorded data about the tips given to the waiters for serving the food. The data recorded by the food server is as follows:

total bill: Total bill in dollars including taxes\ tip : Tip given to waiters in dollars\ sex: gender of the person paying the bill\ smoker: whether the person smoked or not\ day: day of the week\ time: lunch or dinner\ size: number of people in a table

So this is the data recorded by the restaurant. Based on this data, our task is to find the factors affecting waiter tips and train a machine learning model to predict the waiter’s tipping.

# **Importing Libraries**
"""

import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

"""# **EDA**

Exploratory Data Analysis (EDA) is an approach to analyzing datasets with the objective of summarizing their main characteristics, often employing statistical graphics and other data visualization methods. The primary goal of EDA is to gain insights, detect patterns, and understand the structure of the data in order to inform subsequent steps in the data analysis process.

# **Load the dataset**
"""

df = pd.read_csv("tips.csv")

df.head()

df.shape

df.info()

"""# **Missing Values**"""

df.isnull().sum()

"""# **Descriptive Statistics**"""

df.describe()

"""# **Total Bill and Tip**"""

fig = px.histogram(df, x='tip', title='Distribution of Tip Amount')
fig.show()

fig = px.scatter(df, x='total_bill', y='tip', title='Tip Amount vs Total Bill')
fig.show()

correlation = df['total_bill'].corr(df['tip'])
print("Correlation coefficient between total bill and tip:", correlation)

"""The Pearson correlation coefficient between the 'total_bill' and 'tip' variables is approximately 0.676.

This positive correlation indicates a moderately strong linear relationship between the total bill amount and the tip amount. In other words, as the total bill amount increases, the tip amount tends to increase as well.

The Highest Total Bill is 50.810000 and the Lowest is 3.070000

The Hightest Tip is 10.00 and the Lowest Tip is 1.0. Whereas the Average Tip is 2.998279

# **Smoker VS Non-Smoker**
"""

df['smoker'].value_counts()

fig = px.histogram(df, x='smoker', title='Distribution of Smoker', labels={'smoker': 'Smoker'})
fig.show()

"""151 individuals are Not-Smoker and 93 individuals are Smokers

# **Time**
"""

df['time'].value_counts()

fig = px.histogram(df, x='time', title='Distribution of Time', labels={'time': 'Time'})
fig.show()

"""There are 176 instances recorded as 'Dinner' and 68 instances recorded as 'Lunch' in the dataset.

# **Day**
"""

df['day'].value_counts()

fig = px.histogram(df, x='day', title='Distribution of Days', labels={'day': 'Day'})
fig.show()

"""87instances recorded on Saturday, 76 instances recorded on Sunday, 62 instances recorded onThursday, and 19 instances recorded on Friday.

# **Tip Amount by Day**
"""

fig = px.box(df, x='day', y='tip', title='Tip Amount by Day', labels={'day': 'Day', 'tip': 'Tip Amount'})
fig.show()

total_tips_by_day = df.groupby('day')['tip'].sum()
print(total_tips_by_day)

figure = px.pie(df, values='tip', names='day', hole = 0.2)
figure.show()

figure = px.pie(df, values='tip', names='time', hole = 0.5)
figure.show()

fig = px.histogram(df, x='sex', title='Distribution of Gender', labels={'sex': 'Gender'})
fig.show()

fig = px.histogram(df, x='day', color='sex', facet_col='time',
                   title='Gender Distribution based on Time and Day',
                   labels={'day': 'Day', 'sex': 'Gender', 'time': 'Time'},
                   barmode='group')


fig.update_layout(xaxis_title='Day', yaxis_title='Count')


fig.show()

agg_data = df.groupby(['day', 'time'])['tip'].sum().reset_index()


fig = px.sunburst(agg_data, path=['day', 'time'], values='tip', title='Sunburst Chart for Tip Dataset')


fig.show()

"""# **Preprocess the Data**

Convert categorical variables into numerical ones using Label Encoding.
"""

df.head()

"""# **Encoding the Data**"""

label_encoder = LabelEncoder()
df['sex'] = label_encoder.fit_transform(df['sex'])
df['smoker'] = label_encoder.fit_transform(df['smoker'])
df['day'] = label_encoder.fit_transform(df['day'])
df['time'] = label_encoder.fit_transform(df['time'])

df.head()

"""Split the data into training and testing sets"""

X = df.drop('tip', axis=1)
y = df['tip']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# **Machine Learning**

A Linear Regression Model in machine learning is like drawing a straight line through data points to predict a continuous outcome based on input features. It's used to understand how changes in the input features relate to changes in the target variable.
"""

from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit(X_train, y_train)

features = np.array([[24.50, 1, 0, 0, 1, 4]])
model.predict(features)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score


y_pred = model.predict(X_test)


mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print("Mean Absolute Error:", mae)
print("Mean Squared Error:", mse)
print("Root Mean Squared Error:", rmse)
print("R-squared:", r2)

"""Mean Absolute Error (MAE): The average absolute difference between the predicted values and the actual values. In this case, the average difference between the predicted tip amounts and the actual tip amounts is approximately 0.6704.

Mean Squared Error (MSE): The average of the squared differences between the predicted values and the actual values. In this case, the average squared difference between the predicted tip amounts and the actual tip amounts is approximately 0.6948.

Root Mean Squared Error (RMSE): The square root of the average of the squared differences between the predicted values and the actual values. In this case, the square root of the average squared difference between the predicted tip amounts and the actual tip amounts is approximately 0.8336.

R-squared (R2): Also known as the coefficient of determination, R-squared measures the proportion of variance in the target variable that is explained by the model. In this case, approximately 44.41% of the variance in the tip amounts is explained by the model.
"""